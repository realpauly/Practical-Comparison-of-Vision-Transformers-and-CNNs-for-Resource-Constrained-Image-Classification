# -*- coding: utf-8 -*-
"""Copy of CNNs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dcZ67lTZHN7lXiJvN2S3XJ1INVt0RKdd
"""

pip install torch torchvision timm

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from timm.models.vision_transformer import vit_base_patch16_224
from torchvision.models import resnet18
import time
import matplotlib.pyplot as plt
import json

# Hyperparameters
batch_size = 32  # Reduced batch size for lower VRAM usage
learning_rate = 0.001
num_epochs = 10
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Data Loading with Optimized Settings
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize for ViT compatibility
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))  # Normalize
])

train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)

train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)

# Define Models
class VisionTransformerModel(nn.Module):
    def __init__(self, num_classes=10):
        super(VisionTransformerModel, self).__init__()
        self.model = vit_base_patch16_224(pretrained=True)
        self.model.head = nn.Linear(self.model.head.in_features, num_classes)

    def forward(self, x):
        return self.model(x)

class ResNet18Model(nn.Module):
    def __init__(self, num_classes=10):
        super(ResNet18Model, self).__init__()
        self.model = resnet18(pretrained=True)
        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)

    def forward(self, x):
        return self.model(x)

# Training Function with Mixed Precision and Memory Tracking
def train_model(model, train_loader, criterion, optimizer, scaler, device):
    model.train()
    total_loss = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        with torch.cuda.amp.autocast():
            outputs = model(images)
            loss = criterion(outputs, labels)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        total_loss += loss.item()

        # GPU memory usage
        print(f"Memory Allocated: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB")
        print(f"Memory Reserved: {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB")

    return total_loss / len(train_loader)

# Evaluation Function with Memory Tracking
def evaluate_model(model, test_loader, criterion, device):
    model.eval()
    correct = 0
    total = 0
    total_loss = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            with torch.cuda.amp.autocast():
                outputs = model(images)
                loss = criterion(outputs, labels)
            total_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            # GPU memory usage
            print(f"Memory Allocated: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB")
            print(f"Memory Reserved: {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB")

    accuracy = 100 * correct / total
    return total_loss / len(test_loader), accuracy

# Initialize Models and Optimizers
vit_model = VisionTransformerModel(num_classes=10).to(device)
resnet_model = ResNet18Model(num_classes=10).to(device)

criterion = nn.CrossEntropyLoss()
vit_optimizer = torch.optim.Adam(vit_model.parameters(), lr=learning_rate)
resnet_optimizer = torch.optim.Adam(resnet_model.parameters(), lr=learning_rate)

scaler = torch.cuda.amp.GradScaler()  # For mixed precision

# Initialize Logs
vit_training_logs = {'loss': [], 'accuracy': []}
resnet_training_logs = {'loss': [], 'accuracy': []}

# Training and Evaluation
for epoch in range(num_epochs):
    print(f"Epoch {epoch+1}/{num_epochs}")

    start_time = time.time()

    # Train Vision Transformer
    vit_loss = train_model(vit_model, train_loader, criterion, vit_optimizer, scaler, device)
    vit_val_loss, vit_accuracy = evaluate_model(vit_model, test_loader, criterion, device)

    # Train ResNet-18
    resnet_loss = train_model(resnet_model, train_loader, criterion, resnet_optimizer, scaler, device)
    resnet_val_loss, resnet_accuracy = evaluate_model(resnet_model, test_loader, criterion, device)

    elapsed_time = time.time() - start_time

    # Append results to logs
    vit_training_logs['loss'].append(vit_loss)
    vit_training_logs['accuracy'].append(vit_accuracy)
    resnet_training_logs['loss'].append(resnet_loss)
    resnet_training_logs['accuracy'].append(resnet_accuracy)

    print(f"ViT - Loss: {vit_loss:.4f}, Val Loss: {vit_val_loss:.4f}, Accuracy: {vit_accuracy:.2f}%")
    print(f"ResNet18 - Loss: {resnet_loss:.4f}, Val Loss: {resnet_val_loss:.4f}, Accuracy: {resnet_accuracy:.2f}%")
    print(f"Epoch Time: {elapsed_time:.2f} seconds")

# Save Logs to JSON
with open("vit_training_logs.json", "w") as f:
    json.dump(vit_training_logs, f)
with open("resnet_training_logs.json", "w") as f:
    json.dump(resnet_training_logs, f)

# Visualization
# Accuracy Plot
plt.figure(figsize=(10, 5))
plt.plot(vit_training_logs['accuracy'], label='ViT Accuracy')
plt.plot(resnet_training_logs['accuracy'], label='ResNet18 Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Model Accuracy per Epoch')
plt.legend()
plt.show()

# Loss Plot
plt.figure(figsize=(10, 5))
plt.plot(vit_training_logs['loss'], label='ViT Loss')
plt.plot(resnet_training_logs['loss'], label='ResNet18 Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Model Loss per Epoch')
plt.legend()
plt.show()

print("Training Complete!")

import matplotlib.pyplot as plt

import json

# Load data from JSON files
with open('resnet_training_logs.json', 'r') as f:
    resnet_logs = json.load(f)

with open('vit_training_logs.json', 'r') as f:
    vit_logs = json.load(f)


# Extract values for epochs
epochs = list(range(1, 11))

# Accuracy vs Epochs Plot
plt.figure(figsize=(10, 5))
plt.plot(epochs, resnet_logs["accuracy"], label='ResNet-18 Accuracy', marker='o')
plt.plot(epochs, vit_logs["accuracy"], label='ViT Accuracy', marker='o')
plt.title('Model Accuracy per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.grid(True)
plt.savefig('accuracy_comparison.png')
plt.show()

# Loss vs Epochs Plot
plt.figure(figsize=(10, 5))
plt.plot(epochs, resnet_logs["loss"], label='ResNet-18 Loss', marker='o')
plt.plot(epochs, vit_logs["loss"], label='ViT Loss', marker='o')
plt.title('Model Loss per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.savefig('loss_comparison.png')
plt.show()

# Combined Performance Plot
plt.figure(figsize=(10, 5))
plt.plot(epochs, resnet_logs["accuracy"], label='ResNet-18 Accuracy', linestyle='--', marker='o', color='blue')
plt.plot(epochs, vit_logs["accuracy"], label='ViT Accuracy', linestyle='--', marker='o', color='green')
plt.plot(epochs, resnet_logs["loss"], label='ResNet-18 Loss', linestyle='-', marker='x', color='blue')
plt.plot(epochs, vit_logs["loss"], label='ViT Loss', linestyle='-', marker='x', color='green')
plt.title('Combined Performance: Accuracy and Loss')
plt.xlabel('Epoch')
plt.ylabel('Metric Value')
plt.legend()
plt.grid(True)
plt.savefig('combined_performance.png')
plt.show()